---
title: "An introduction to tidyverse and GGPLOT2"
author: "Bioinformatics Core"
output:
  html_document:
    keep_md: TRUE
---

Tidyverse is a set of package for doing data science.  [R for Data Science](https://r4ds.had.co.nz/index.html) by Garrett Grolemund, Hadley Wickham model Data Science in the following way.

![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/Intro_to_tidyverse_and_ggplot2_images/R-data-science.png)

```{r setup}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

We will start learning about Tidyverse tools by starting at the first step in this process, importing data.

***

## Step 1: Import data with [readr](https://readr.tidyverse.org/) ![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/Intro_to_tidyverse_and_ggplot2_images/readr.png)

> “The goal of 'readr' is to provide a fast and friendly way to read rectangular data (like 'csv', 'tsv', and 'fwf'). It is designed to flexibly parse many types of data found in the wild, while still cleanly failing when data unexpectedly changes.”
>

The readr package gets loaded automatically when you use library(tidyverse), or you can load it directly.
```{r readr}
library(readr)
```

***


#### readr supports a number of file formats with different read_* functions including:

* read_csv(): comma separated (CSV) files
* read_tsv(): tab separated (TSV) files
* read_delim(): general delimited files (you must supply delimiter!)
* read_fwf(): fixed width files           
* read_table(): tabular files where columns are separated by white-space.
* read_log(): web log files

#### Readr also has functions write data in a number of formats with various write_* functions:

* write_csv(): comma separated (CSV) files
* write_tsv(): tab separated (TSV) files
* write_delim(): general delimited files
* write_excel_csv(): comma separated files for Excel

***

#### Get some data and try out these functions:

Note that this data set is from the ggplot2 package.

```{r read_tsv1}
read_tsv("https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/mpg.tsv")
```

Alternatively we could use another of the readr functions, **read_lines**, to look at the first few lines of the file:

```{r read_lines1}
read_lines("https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/mpg.tsv", n_max = 5)
```

We could also check the number of lines by reading the whole file and counting the lines. This approach will be slow for large files:
```{r read_lines2}
length(read_lines("https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/mpg.tsv"))
```

Using the functions you just ran, answer the following questions:

* How many lines does the file have?
* What is the first line of the file?
* What separates the values in the file?

***

To read the file and store it in an object, we assign the output of the read_tsv function to an object.

```{r read_tsv2}
mpg <- read_tsv('mpg.tsv')
```

#### What are "Column Specifications"?

Computers use different types of containers to store different types of data. In tidyverse all numeric data (floating point and integer) is [stored as a 64-bit double](https://www.tidyverse.org/blog/2018/12/readr-1-3-1/). Data that is not numeric is stored in character vectors. When reading a file, readr must make a guess about the type of data stored in each column. To do this, readr skims the [first 1000 lines](https://readr.tidyverse.org/articles/readr.html) of the file, investigating the values it finds there, and using them to make a guess at the format of the file.

***

#### Now, let's look at the object we just loaded

* Does the object have the expected number of lines?
* What type of object is it?

```{r}
mpg
class(mpg)
is_tibble(mpg)
```

### What is a [Tibble](https://tibble.tidyverse.org/)? ![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop//Intro_to_tidyverse_and_ggplot2_images/hex-tibble.png)

Tibbles are a modified type of data frame. Everything you have learned about accessing and manipulating data frames still applies, but a tibble behaves a little differently. The documentation describes them like this:

>Tibbles are data.frames that are lazy and surly: they do less (i.e. they don’t change variable names or types, and don’t do partial matching) and complain more (e.g. when a variable does not exist). This forces you to confront problems earlier, typically leading to cleaner, more expressive code.
>

#### Creating tibbles

As we saw above, importing data using the readr package creates a tibble. Additionally, tibbles can be created from existing objects using as_tibble(),
```{r}
head(iris)
as_tibble(iris)
```

created manually by specifying each column,
```{r}
tibble(
        column1=1:5,
        column2=c("a","b","c","d","e"),
        column3=pi*1:5
       )
```

or row-by-row with tribble().
```{r}
tribble(
  ~x, ~y,  ~z,
  "a", 2,  3.6,
  "b", 1,  8.5
)
```

Tibbles can have terrible column names that should never be used. **Good practice is to have unique column names that start with a letter and contain no special characters.**
```{r}
tibble(
  `terrible column 1` = 1:5,
  `no good :)` = letters[1:5],
  `;very-bad/` = sin(4:8)
)
```

***

#### Challenge

Create a tibble with 100 rows and 3 columns, write your tibble to a file, and read it back in.
  * Write it out using **write_tsv()**
  * Which function should you use to read back in?
      * Try **read_csv()**. Did it read in successfully?
      * Try to use **read_delim()**. Did that work any better? *hint: specify delimiter*

```{r challenge1}

```


#### Advanced challenge

Try to generate a [*parsing failure*](https://r4ds.had.co.nz/data-import.html) in readr by creating and writing a tibble that causes problems when read in by read_delim.

```{r challenge2}

```

Then create R code that allows read_delim to successfully load your treacherous tibble.
```{r challenge3}

```

***


## Step 2: Tidy data with [tidyr](https://tidyr.tidyverse.org/) ![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/Intro_to_tidyverse_and_ggplot2_images/hex-tidyr.png)

#### First, what is "tidy" data?

> Tidy data is data where:
>
> 1) Every column is a variable.
>
> 2) Every row is an observation.
>
> 3) Every cell is a single value.
>
> Tidy data describes a standard way of storing data that is used wherever possible throughout the tidyverse. If you ensure that your data is tidy, you’ll spend less time fighting with the tools and more time working on your analysis.
>
[**Wickham, Hadley. "Tidy data." Journal of Statistical Software 59.10 (2014): 1-23.**](https://vita.had.co.nz/papers/tidy-data.pdf)

Definitions:

* A **variable** stores a set of values of a particular type (height, temperature, duration)

* An **observation** is all values measured on the same unit across variables

***

#### There is more than one way we can store data from an experiment.

```{r tidy_data1}
d1 = data.frame(
        mouse_id = rep(c("A1","A2","A3"), 2),
        treatment = rep(c('a','b'), each = 3),
        mass = c(4,6,9,8,5,4)
)
d2 <- data.frame(
        A1=c(4,8),
        A2=c(6,5),
        A3=c(9,4)
)
rownames(d2) <- c("a","b")
d1
d2
```

**Is either of these ways of organizing our experiment tidy? Why or why not?**

Remember, for "tidy" data, we're looking for a table where:

1. Every column is a variable
2. Every row is an observation
3. Every cell is a single value

In the two tables above, what are the variables and observations? Where are they stored?

***

#### How do we make our data "tidy?"

First, make the row names into a new column with the **rownames_to_column()** function:
```{r tidy_data2}
d2.1 <- rownames_to_column(d2, 'treatment')
d2.1
```

Make each row an observation with **pivot_longer()** function:
```{r tidy_data3}
d2.2 <- pivot_longer(d2.1, cols = -treatment, names_to = "mouse_id", values_to = "mass")
d2.2
```

Reorder columns for looks using **select()** function:
```{r tidy_data4}
d2.3 <- select(d2.2, mouse_id, treatment, mass)
d2.3
```

***

### Piping commands together with [magrittr](https://magrittr.tidyverse.org/) ![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/Intro_to_tidyverse_and_ggplot2_images/magrittr.png)
Although the code above is fairly readable, it is not compact. It also creates three copies of the data (d2.1, d2.2, d2.3). We could use a couple of different strategies for carrying out this series of operations in a more concise manner.

#### The base-R strategy, Nested Functions
Traditionally, R users have used nested functions to skip the creation of intermediary objects:
```{r tidy_nest}
d3 <- select( pivot_longer(rownames_to_column(d2, 'treatment'),
                             cols = -treatment,
                             names_to = "mouse_id",
                             values_to = "mass"),
                mouse_id, treatment, mass)
d3
identical(d2.3, d3)
```


#### The tidyverse option, using the %>% pipe operator

> The magrittr package offers a set of operators which make your code more readable by:
>
> * structuring sequences of data operations left-to-right (as opposed to from the inside and out),
> * avoiding nested function calls,
> * minimizing the need for local variables and function definitions, and
> * making it easy to add steps anywhere in the sequence of operations.

```{r tidy_pipe}
d4 <-
  d2 %>% rownames_to_column('treatment') %>%
    pivot_longer(cols = -treatment,
                 names_to = "mouse_id",
                 values_to = "mass") %>%
    select(mouse_id, treatment, mass)
d4
identical(d2.3, d4)
```

#### How does %>% work?

By default, %>% works to replace the first argument in a function with the left-hand side value with basic piping:

* x %>% f is equivalent to f(x)
* x %>% f(y) is equivalent to f(x, y)
* x %>% f %>% g %>% h is equivalent to h(g(f(x)))

In more complicated situations you can also specify the argument to pipe to using the argument placeholder:

* x %>% f(y, .) is equivalent to f(y, x)
* x %>% f(y, z = .) is equivalent to f(y, z = x)

***

#### Data can be made "wider" as well as "longer"

In addition to pivot_longer(), which we used above, we can change the shape of our data table using **pivot_wider()**, it does the inverse transformation of **pivot_longer()** and adds columns by removing rows.

The pivot_wider() function adds columns by removing rows. For example:
```{r pivot_wider}
d1
pivot_wider(d1, names_from = mouse_id, values_from = mass )
```

***

#### Separating values from a column that contains two or more variables

Sometimes a column contains two variables split by a delimiter. The **separate()** function can be used to create two columns from this single input. The tidyr package includes an example of this for us to practice with:
```{r separate1}
table3
```

The third column **rate** contains two different values, **cases** and **population**. We can use the **separate()** function to split these into two columns.
```{r separate2}
separate(data = table3, col = rate, into = c("cases", "population"), sep = '/')
```

#### Challenge

Tidy the relig_income example data table included in the tidyr package. *hint:  what are the variables and observations in this dataset?*

```{r challenge4}

```

What is wrong with the example data table2 from the tidyr package? What is wrong with table2? How many rows does it have per observation? Tidy it.
```{r challenge5}

```

***

## Step 3, Transform data with dplyr ![](./Intro_to_tidyverse_and_ggplot2_images/hex-dplyr.png)

The dplyr package provides a set of verbs for modifying, combining, and otherwise transforming variables, creating subsets based on various attributes, combining multiple tibbles, etc. These approaches are meant to enable efficient manipulation of data. Functions include:

* mutate() adds new variables that are functions of existing variables
* select() picks variables based on their names
* filter() picks cases based on their values
* summarize() reduces multiple values down to a single summary
* arrange() changes the ordering of the rows

To demonstrate some of them we will use the starwars dataset included in the dplyr package.

```{r dplyr}
library(dplyr)
starwars
```

For example, using mutate, we can calculate the [BMI](https://www.cdc.gov/healthyweight/assessing/bmi/adult_bmi/index.html) of characters in the Star Wars universe.
```{r bmi1}
starwars %>% mutate(BMI = mass / (height/100))
```

As we saw above, select() allows us to limit the output to specified columns based on name or index.
```{r bmi2}
starwars %>% mutate(BMI = mass / (height/100)) %>% select(name, species, BMI)
```
Before we calculate any summary statistics, we need to check to see if we have appropriate levels of replication. We can determine the number of samples per species using count().
```{r bmi3}
starwars %>% count(species, sort = TRUE, name = "Samples")
```

Species information is missing for a number of samples, so we can remove these with drop_na(), and also remove any samples for which mass or height is NA (since that will interfere with our BMI calculation).
```{r bmi4}
starwars %>% drop_na(species, mass, height) %>% count(species, sort=T, name = "Samples")
```

To calculate the mean BMI for all species with at least three samples, we can combine several operators, piping them together with the %>% as we saw above in the section on tidying data. In order, we will:

1. Drop observations with missing species, mass, or height with **drop_na()**
2. Calculate BMI for remaining observations using **mutate()**
3. Group observations by species with **group_by()**
4. Remove all species with fewer than 3 observations using **filter** and **n()**
5. Calculate mean BMI of each species with **summarize**

We can drop observations for species for which there isn't sufficient replication using a combination of **filter()**, **group_by** and a special **n()** function.

```{r bmi5}
starwars %>% drop_na(species, mass, height) %>%
  mutate(BMI = mass / (height/100)) %>%
  group_by(species) %>%
  filter(n() >= 3) %>%
  summarize(mean_BMI = mean(BMI))
```

***

So far, we've used all of the functions listed except arrange. What does arrange do? According to the documentation, arrange "changes the ordering of the rows." This might be useful if we wanted to find the tallest inhabitant of each of the planets sampled in starwars.
```{r tallest}
starwars %>%
  arrange(homeworld, desc(height)) %>%  # sort by homeworld, then height descending
  group_by(homeworld) %>%  # use group_by to tell slice() how to select records
  slice(1)  # keep only the first observation per homeworld
```

***

#### Challenge

Use the data transformation functions to investigate flights into and out of NYC. This data can be found in the flights dataset from the nycflights13 package. First install the package and take a look at the data.

```{r install_nycflights13}
if (!any(rownames(installed.packages()) == "nycflights13")){
  install.packages("nycflights13")
}
library(nycflights13)
flights
```

Assuming that people traveling for the Christmas/New Years holiday depart between December 20th and 24th,
  * from which airport (EWR, JFK, LGA) did the most flights travel to San Francisco Airport (SFO)?
  * How many of these flights were delayed in departure by at least 30 minutes?
  * How many of these flights arrived late by at least 30 minutes?
  * What was the shortest in-flight time to SFO from each of the airports?

```{r challenge6}

```

#### Advanced challenge

Answer the questions above using base R.
```{r challenge7}

```

***

## Step 4, Visualise with ggplot2 ![](https://raw.githubusercontent.com/ucdavis-bioinformatics-training/2020-Bioinformatics_Prerequisites_Workshop/master/Intro_to_R/Intro2R/Intro_to_tidyverse_and_ggplot2_images/hex-ggplot2.png)

Based on [The Grammar of Graphics](https://www.amazon.com/Grammar-Graphics-Statistics-Computing/dp/0387245448/ref=as_li_ss_tl?ie=UTF8&qid=1477928463&sr=8-1&keywords=the+grammar+of+graphics&linkCode=sl1&tag=ggplot2-20&linkId=f0130e557161b83fbe97ba0e9175c431), [ggplot2](https://ggplot2.tidyverse.org/) is a popular system for creating graphics in a "declarative" way. This means that you provide the data, tell ggplot2 how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.

**Most of the following material on ggplot2 was taken directly from [RStudio teaching resources](https://github.com/rstudio-education) that are made freely available online.**

***

The template for creating a plot with ggplot looks like this:

> ggplot(data = \<DATA\>) +
  \<GEOM_FUNCTION\>(mapping = aes(<MAPPING>) )
>

The **geom** is a "geometric object" (e.g. geom_boxplot, geom_dotplot, etc.) that describes how the data is to be displayed, and the the **aes** or "aesthetics," are visual properties of the graphical output (e.g. color, shape, or size). When we call ggplot using this format, we are "mapping," or connecting, values in the data to visual element of the plot such as the color, shape, or size of points.
```{r ggplot}
ggplot(data = mpg) +
  geom_point(mapping = aes(x = displ, y = hwy, color = cyl))
```

There are many [geoms](https://ggplot2.tidyverse.org/reference/) and [aesthetics](https://ggplot2.tidyverse.org/articles/ggplot2-specs.html) available in ggplot2, and by combining these we can communicate a great deal about our data.

#### Challenge

Create scatter plots from the mpg dataset. Experiment with mapping aesthetics to different variables.

  * How does the behavior of ggplot differ when you use the "class" variable vs the "cty variable for color?
  * What happens when you use more than one aesthetic?
  * What happens if you try to specify an aesthetic mapping outside of the aes() function?

```{r challenge8}

```

Create a tibble with x coordinates, y coordinates, 6 colors (color1-6), and 6 shapes (shape1-6).

  * Plot your tibble.
  * Try to set the size of all points to something larger than the default.
  * Does the tibble behave in the same way as the mpg data frame?
```{r challenge9}

```

***

Plots can be built up piece by piece and only plotted when they are ready.

This code will not produce a plot:

q <- ggplot(mpg) + geom_point(aes(x = displ, y = hwy))



**Facets** are another way to display groupings in your data. Only instead of color or shape, facets display each group in a different plot.


#### Challenge

Experiment with each of the modifications to the _q_ object below.
  * How does facet_grid() work?
  * How does facet_wrap() differ from facet_grid()?
  * What happens when you provide two variables to facet_wrap()?
```{r layers}
q <- ggplot(mpg) + geom_point(mapping = aes(x = displ, y = hwy))
q + facet_grid(. ~ cyl)
q + facet_grid(drv ~ .)
q + facet_grid(drv ~ cyl)
q + facet_wrap(~ class)
```

In addition to the aesthetics, ggplot2 allows you access to the labels on your plot, which you can modify to better communicate your findings.
```{r labels}
ggplot(data = mpg) +
  geom_point(mapping = aes(displ, hwy, color = class)) +
  labs(title = "Fuel Efficiency by Engine Size",
    subtitle = "Data facetted by class",
    x = "Engine Size (displacement in liters)",
    y = "Fuel Efficiency (MPG)",
    color = "Class of\nAutomobile",
    caption = "Data from the EPA") +
    facet_wrap(~ class)
```

So far, we've mostly been working with geom_point. However, ggplot provides many other geoms, including:

  * geom_abline()
  * geom_boxplot()
  * geom_histogram()
  * geom_smooth()
  * geom_violin()

and many more. For each of these geoms, the available aesthetics can be mapped to the data, and may have additional parameters to modify that can change the appearance of the plot.

#### A plot may use one or more geoms

For example, this box plot and histogram each use a single geom. The geom_histogram function takes an additional argument that allows the user to set the binwidth and get a higher or lower resolution plot.
```{r single_geom}
ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = class, y = hwy))
ggplot(data = mpg) +
  geom_histogram(mapping = aes(x = hwy), binwidth=1)
```

If two (or more) geoms use the same type of axes, they can be displayed on the same plot. In this case, we can use both points and smoothed conditional means.
```{r multiple_geom}
ggplot(mpg) +
  geom_point(aes(displ, hwy)) +
  geom_smooth(aes(displ, hwy))
```


#### Aesthetic mapping may be set for the entire plot, or for each layer individually.

```{r local_global}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(mapping = aes(color = drv)) +
  geom_smooth()
ggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +
  geom_point() +
  geom_smooth()
```

This concept also applies to data. If you only want a subset of your data plotted by one of your geoms, you can specify a second data set inside of the function call to that geom.
```{r local_global2}
myplot <- ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(mapping = aes(color = drv)) +
  geom_smooth(data = filter(mpg, drv == "f"))
myplot
```


#### Once we have finished creating our plot, we have two ways to save the plot.

Option 1, using base-R png() or pdf() functions:
```{r save1}
pdf(file="myplot.pdf", width = 5, height = 5)
myplot
dev.off()

png(file="myplot.png", width = 500, height = 500)
myplot
dev.off()
```


Option 2, using the ggsave function. By default, ggsave will save the last plot made, to save a different plot, we can specify another plot instead.
```{r save2}
p <- ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +
  geom_point(mapping = aes(color = drv)) +
  geom_smooth()

ggsave(file = "myplot2.pdf", width = 5, height = 5)
ggsave(file = "myplot2.pdf", width = 5, height = 5, plot = myplot)
?ggsave
```


#### Keep exploring

Visit <https://rstudio.cloud/learn/cheat-sheets> and download the Data Visualization cheatsheet. Experiment with different geoms, getting a good mix of one variable, two variables, continuous, and discrete.
